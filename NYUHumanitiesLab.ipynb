{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Internet Archive offers an API (Application Programming Interface) that makes it easier to access their archives programmatically. For a given item, say [the first issue of Scientific American](https://archive.org/details/scientific-american-1845-08-28), we can get the metadata for the item by changing the URL.\n",
    "\n",
    "| Data View | URL |\n",
    "| --- | --- |\n",
    "| Pretty Web Page for Humans | [https://archive.org/**details**/scientific-american-1845-08-28](https://archive.org/details/scientific-american-1845-08-2)|\n",
    "| Easy Metadata for Machines | [https://archive.org/**metadata**/scientific-american-1845-08-28](https://archive.org/metadata/scientific-american-1845-08-28) |\n",
    "\n",
    "The metadata is offered in a standard format called [JSON](https://en.wikipedia.org/wiki/JSON). JSON is a standard format for communicating chunks of simple data in a way that is human-readable and machine-parseable.\n",
    "\n",
    "Let's take a look at what the JSON for the above item looks like:\n",
    "\n",
    "    {\"created\":1448448826,\"d1\":\"ia600806.us.archive.org\",\"d2\":\"ia700806.us.archive.org\",\"dir\":\"/34/items/scientific-american-1845-08-28\",\"files\":[{\"name\":\"scientific-american-v01-n01-1845-08-28.djvu\",\"source\":\"derivative\",\"format\":\"DjVu\",\"original\":\"scientific-american-v01-n01-1845-08-28_djvu.xml\",\"mtime\":\"1329085972\",\"size\":\"1054500\",\"md5\":\"e24b0db3861efd985ed11172ec0f5677\",\"crc32\":\"a156ba3a\",\"sha1\":\"7ca3d6ce76717b19ba91a3baaecbe6bb7b897d10\"},{\"name\":\"scientific-american-v01-n01-1845-08-28.epub\",\"source\":\"derivative\",\"format\":\"EPUB\",\"original\":\"scientific-american-v01-n01-1845-08-28_abbyy.gz\",\"mtime\":\"1329085978\",\"size\":\"97103\",\"md5\":\"b27bd43cf6af61d6e70a6d135e2178e9\",\"crc32\":\"3c9a3d5f\",\"sha1\":\"474c04d1000809886afe0c52712735be890c2057\"},...\n",
    "\n",
    "Now at first glance, this is...not human-readable. But let's consider the data in a different way: as a table.\n",
    "\n",
    "| Key | Value |\n",
    "| --- | --- |\n",
    "| \"created\" | 1448448826 |\n",
    "| \"d1\" | \"ia600806.us.archive.org\" |\n",
    "| \"d2\" | \"ia700806.us.archive.org\" |\n",
    "| \"dir\" | \"/34/items/scientific-american-1845-08-28\"|\n",
    "| \"files\" | [{\"name\":...}] |\n",
    "\n",
    "Still esoteric, but more organized. A piece of JSON data relates keys to values, much like how a phone book relates names to phone numbers. But what do the values mean? \n",
    "\n",
    "Whelp, one of the unfortunate things about JSON is that, while the _format_ is universally understood, the _meanings_ for keys and values are not standardized across the web.\n",
    "\n",
    "Here, for example, the Internet Archive somewhat curiously decided that \"created\" should refer to when the request was first made, as seconds since midnight, January 1st, 1970 (or what is called the [Unix Epoch](https://en.wikipedia.org/wiki/Unix_time)). So that ```1448448826``` refers to Wed, 25 Nov 2015 10:53:46. If Bard's library were to implement a JSON API for their collections, they might decide to use the key \"created\" to refer to when the item was first uploaded, or first published, or first acquired. Facebook might use \"created\" to refer to when a particular user first joined Facebook, or when a user was born. And so on.\n",
    "\n",
    "The upshot is that, while JSON is great for getting information from Web Point A to Web Point B, there's still the need to process and interpret that information according to how the publisher meant for it to be interpreted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import internetarchive as ia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line loads the \"internetarchive\" library for python, and gives it a shorter name (\"ia\") for brevity's sake. This library handles communicating with the Internet Archive, and deals with interpreting the JSON for us. Now we run a search for a particular collection, and print out how many documents we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870\n"
     ]
    }
   ],
   "source": [
    "search_results = ia.search_items('collection:scientific-american-1845-1909')\n",
    "print(search_results.num_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Once you've read through this notebook and get what's going on, try replacing ```scientific-american-1845-1909``` with the name of a collection you're interested in. You can get the name by going to the collection in your browser and looking at the last part of the URL.)\n",
    "\n",
    "Right now, the ```search_results``` variable is just a pointer to the search. But in order to get the actual IDs for all the items in the collection, we need to perform that search and store what it returns in something we can process further, like a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_items = list(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the list contains. This should print out the IDs for first ten items on the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: scientific-american-1845-08-28\n",
      "ID: scientific-american-1846-03-19\n",
      "ID: scientific-american-1846-03-26\n",
      "ID: scientific-american-1846-04-02\n",
      "ID: scientific-american-1846-04-09\n",
      "ID: scientific-american-1846-04-16\n",
      "ID: scientific-american-1846-04-23\n",
      "ID: scientific-american-1846-04-30\n",
      "ID: scientific-american-1846-05-06\n",
      "ID: scientific-american-1846-05-14\n"
     ]
    }
   ],
   "source": [
    "for item in search_items[0:10]:\n",
    "    print(\"ID: {}\".format(item['identifier']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we know the IDs of what we're interested in, we can work with those items. Let's get a list of the file types associated with that first item returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_item = ia.get_item(search_items[0]['identifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That line is a little dense, so let's break it down, starting from the inside and working our way out.\n",
    "1. ```search_items``` is that same list of items and IDs from above.\n",
    "2. ```search_items[0]``` gets the first item of that list (remember: computers start counting from zero!)\n",
    "3. ```search_items[0]['identifier']``` gets the value for the ```identifier``` key of that first item.\n",
    "4. ```ia.get_item(search_items[0]['identifier'])``` takes that identifer value for the first item and asks the Internet Archive for all the information it has.\n",
    "5. Finally, we keep that information in the ```first_item``` variable for later processing.\n",
    "\n",
    "Let's get a listing of all the files associated with this item. There are quite a lot, so let's just look at the first two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'crc32': 'a156ba3a',\n",
       "  'format': 'DjVu',\n",
       "  'md5': 'e24b0db3861efd985ed11172ec0f5677',\n",
       "  'mtime': '1329085972',\n",
       "  'name': 'scientific-american-v01-n01-1845-08-28.djvu',\n",
       "  'original': 'scientific-american-v01-n01-1845-08-28_djvu.xml',\n",
       "  'sha1': '7ca3d6ce76717b19ba91a3baaecbe6bb7b897d10',\n",
       "  'size': '1054500',\n",
       "  'source': 'derivative'},\n",
       " {'crc32': '3c9a3d5f',\n",
       "  'format': 'EPUB',\n",
       "  'md5': 'b27bd43cf6af61d6e70a6d135e2178e9',\n",
       "  'mtime': '1329085978',\n",
       "  'name': 'scientific-american-v01-n01-1845-08-28.epub',\n",
       "  'original': 'scientific-american-v01-n01-1845-08-28_abbyy.gz',\n",
       "  'sha1': '474c04d1000809886afe0c52712735be890c2057',\n",
       "  'size': '97103',\n",
       "  'source': 'derivative'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_item.files[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want PDFs, right? But take a look at the PDF files associated with the item with id 'scientific-american-1898-11-12':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'crc32': '482d2aed',\n",
       "  'format': 'Image Container PDF',\n",
       "  'md5': 'eeb493b3fb722f839bc9a92e5427be62',\n",
       "  'mtime': '1329172430',\n",
       "  'name': 'scientific-american-v79-n20-1898-11-12.pdf',\n",
       "  'sha1': 'dcb1e1443e4d049195f2e5ea75ad94ac65d2fed2',\n",
       "  'size': '10096731',\n",
       "  'source': 'original'},\n",
       " {'crc32': '301df72b',\n",
       "  'format': 'Additional Text PDF',\n",
       "  'md5': '3ae6328f04fb3847da845e5b79bb2bd6',\n",
       "  'mtime': '1329178757',\n",
       "  'name': 'scientific-american-v79-n20-1898-11-12_text.pdf',\n",
       "  'original': 'scientific-american-v79-n20-1898-11-12_djvu.xml',\n",
       "  'sha1': '9a35631132cf87c58801543753fe2569ffc8f6e7',\n",
       "  'size': '3437337',\n",
       "  'source': 'derivative'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uh_oh = ia.get_item('scientific-american-1898-11-12')\n",
    "[file for file in uh_oh.files if \"PDF\" in file['format']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of PDF: Full image containers, and those processed by OCR software to compress and represent text. For our purposes, we don't really care which we get -- we just want one.\n",
    "\n",
    "That second line is an example of a thing in Python called a *list comprehension*. It's basically shorthand for the specific case of constructing a list using a ```for``` loop. That line is functionally the same as doing this:\n",
    "\n",
    "```\n",
    "pdf_files = []\n",
    "for file in uh_oh.files:\n",
    "    if \"PDF\" in file['format']:\n",
    "        pdf_files.append(file)\n",
    "print(pdf_files)\n",
    "```\n",
    "\n",
    "...but it's clearly a lot shorter.\n",
    "\n",
    "\n",
    "So let's download PDFs for the first 10 documents.\n",
    "First we make a directory to store the documents in, if it doesn't already exist.\n",
    "Then we download and save the needed files to that directory.\n",
    "We also record the filenames of each pdf for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting file scientific-american-v01-n01-1845-08-28.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n27-1846-03-19.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n28-1846-03-26.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n29-1846-04-02.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n30-1846-04-09.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n31-1846-04-16.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n32-1846-04-23.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n33-1846-04-30.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n34-1846-05-06.pdf...\n",
      "Gotten!\n",
      "Getting file scientific-american-v01-n35-1846-05-14.pdf...\n",
      "Gotten!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from requests import ConnectionError\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"DownloadedPDFs\")\n",
    "except FileExistsError:\n",
    "    # if it already exists, then don't worry about making it.\n",
    "    pass\n",
    "\n",
    "files = []\n",
    "\n",
    "for search_item in search_items[0:10]:\n",
    "    item_id = search_item['identifier']\n",
    "    item = ia.get_item(item_id)\n",
    "    filenames = [f['name'] for f in item.files if 'PDF' in f['format']]\n",
    "    if len(filenames) == 0:\n",
    "        print(\"Ooops, looks like the item with id {} has no PDFs!\".format(item_id))\n",
    "    else:\n",
    "        fn  = filenames[0]\n",
    "        print(\"Getting file {}...\".format(fn))\n",
    "        file = item.get_file(fn) \n",
    "        try:\n",
    "            filename = os.path.join(\"DownloadedPDFs\", fn)\n",
    "            file.download(filename, silent=True)\n",
    "            files.append(filename)                   \n",
    "            print(\"Gotten!\")\n",
    "        except ConnectionError:\n",
    "            print(\"Oops, there's a connection error. Try to get {} again later\".format(fn))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, now we've got our PDFs! Here's a function that converts a pdf to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wand.image import Image\n",
    "\n",
    "def convert_pdf(pdf_filename, converted_dir = \"converted\", to_directory=True):\n",
    "    magazine_name = os.path.basename(pdf_filename)\n",
    "    magazine_name, _ = os.path.splitext(magazine_name)\n",
    "    try:\n",
    "        os.mkdir(converted_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    if to_directory:\n",
    "        converted_dir = os.path.join(converted_dir, magazine_name)\n",
    "        try:\n",
    "            os.mkdir(converted_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "    with Image(filename=pdf_filename, resolution=200) as magazine:\n",
    "        for page in magazine.sequence:\n",
    "            i = magazine.sequence.index(page) + 1\n",
    "            print(\"Converting page {}\".format(i))\n",
    "            converted = Image(page).convert('jpg')\n",
    "            \n",
    "            # Make filename for converted files from pdf filename\n",
    "            converted_filename, _ = os.path.splitext(magazine_name)\n",
    "            converted_filename += \"-pg{}.jpg\".format(i)\n",
    "            converted_filename = os.path.join(converted_dir, converted_filename)\n",
    "            \n",
    "            converted.save(filename=converted_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting page 1\n",
      "Converting page 2\n",
      "Converting page 3\n",
      "Converting page 4\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    convert_pdf(file, to_directory=False)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
